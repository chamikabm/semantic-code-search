{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Indexing Embeddings in a Vector Database\n",
    "\n",
    "This notebook demonstrates the final step in preparing our search system: taking our code chunks and their embeddings and storing them in a **vector database**. For this demo, we'll use **Qdrant**.\n",
    "\n",
    "## Prerequisites: Starting the Database with Docker Compose\n",
    "\n",
    "1.  **Save the `docker-compose.yml` file** provided in the article to this directory.\n",
    "2.  **Run the command:** Open your terminal in this directory and run `docker-compose up -d`.\n",
    "3.  **Verify:** Check that the Qdrant dashboard is running at [http://localhost:6333/dashboard](http://localhost:6333/dashboard)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install necessary libraries\n",
    "!pip install openai python-dotenv qdrant-client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup Clients (OpenAI and Qdrant)\n",
    "\n",
    "We'll set up our clients by loading the OpenAI API key from a `.env` file and connecting to our local Qdrant instance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instructions for Using a `.env` File\n",
    "\n",
    "1.  **Create a file:** In the same directory as this notebook, create a file named `.env` or rename provided `.env_example` to `.env`\n",
    "2.  **Add your key:** Open it and add your OpenAI API key like this:\n",
    "    `OPENAI_API_KEY=\"sk-YourSecretKeyGoesHere\"`\n",
    "3.  **Save the file.** The code below will automatically load it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ OpenAI client initialized successfully!\n",
      "‚úÖ Qdrant client connected successfully!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import getpass\n",
    "import uuid\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "from qdrant_client import QdrantClient, models\n",
    "\n",
    "# --- OpenAI Client Setup ---\n",
    "load_dotenv()\n",
    "api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
    "if not api_key:\n",
    "    api_key = getpass.getpass(\"OpenAI API key not found. Please enter your key: \")\n",
    "    os.environ[\"OPENAI_API_KEY\"] = api_key\n",
    "\n",
    "try:\n",
    "    openai_client = OpenAI()\n",
    "    print(\"‚úÖ OpenAI client initialized successfully!\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error initializing OpenAI client: {e}\")\n",
    "\n",
    "# --- Qdrant Client Setup ---\n",
    "try:\n",
    "    qdrant_client = QdrantClient(\"localhost\", port=6333)\n",
    "    # Check if the client can communicate with the server.\n",
    "    qdrant_client.get_collections()\n",
    "    print(\"‚úÖ Qdrant client connected successfully!\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error connecting to Qdrant: {e}\")\n",
    "    print(\"‚ö†Ô∏è Please ensure the Qdrant Docker container is running via docker-compose.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Prepare Enriched Data and Create Embeddings\n",
    "\n",
    "Here, we'll implement the **hybrid approach**: for each chunk, we'll create a combined text string containing both the **LLM-generated description** and the **raw code**. This combined text is what we'll send to OpenAI to create a single, powerful embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Generating Hybrid Embeddings ---\n",
      "\n",
      "Embedding chunk: read_file_content...\n",
      "  ‚úì Embedding created (Dimensions: 1536)\n",
      "\n",
      "Embedding chunk: validate_email...\n",
      "  ‚úì Embedding created (Dimensions: 1536)\n",
      "\n",
      "Embedding chunk: DataProcessor...\n",
      "  ‚úì Embedding created (Dimensions: 1536)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# This list represents our chunks with AI-generated descriptions and rich metadata\n",
    "enriched_chunks = [\n",
    "    {\n",
    "        'name': 'read_file_content', 'type': 'function', 'llm_description': 'Reads and returns the entire content of a specified file, handling file-not-found errors gracefully.', \n",
    "        'code': 'def read_file_content(filepath: str) -> str:\\n    \"\"\"Read and return the content of a file.\"\"\"\\n    try:\\n        with open(filepath, \\'r\\', encoding=\\'utf-8\\') as file:\\n            return file.read()\\n    except FileNotFoundError:\\n        return \"\"',\n",
    "        'file_path': 'src/utils/file_handler.py', 'line_from': 10, 'line_to': 15\n",
    "    },\n",
    "    {\n",
    "        'name': 'validate_email', 'type': 'function', 'llm_description': 'Performs a simple validation of an email address by checking for the presence of ‚Äú@‚Äù and ‚Äú.‚Äù symbols.', \n",
    "        'code': 'def validate_email(email: str) -> bool:\\n    \"\"\"Simple email validation function.\"\"\"\\n    return \"@\" in email and \".\" in email.split(\"@\")[-1]',\n",
    "        'file_path': 'src/utils/validators.py', 'line_from': 8, 'line_to': 10\n",
    "    },\n",
    "    {\n",
    "        'name': 'DataProcessor', 'type': 'class', 'llm_description': 'A class designed to process and analyze batches of string data, including cleaning and calculating statistics.', \n",
    "        'code': 'class DataProcessor:\\n    \"\"\"A class for processing and analyzing data.\"\"\"\\n\\n    def __init__(self, data_source: str):\\n        self.data_source = data_source\\n        self.processed_count = 0\\n\\n    def process_batch(self, items: List[str]) -> List[str]:\\n        #... (rest of class code)',\n",
    "        'file_path': 'src/processing/core.py', 'line_from': 20, 'line_to': 45\n",
    "    }\n",
    "]\n",
    "\n",
    "def get_openai_embedding(text: str, model: str = \"text-embedding-3-small\"):\n",
    "    text = text.replace(\"\\n\", \" \")\n",
    "    try:\n",
    "        return openai_client.embeddings.create(input=[text], model=model).data[0].embedding\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error generating embedding: {e}\")\n",
    "        return None\n",
    "\n",
    "# --- Generate embeddings for the combined text ---\n",
    "print(\"--- Generating Hybrid Embeddings ---\\n\")\n",
    "for chunk in enriched_chunks:\n",
    "    combined_text = f\"Description: {chunk['llm_description']}\\n---\\nCode:\\n{chunk['code']}\"\n",
    "    print(f\"Embedding chunk: {chunk['name']}...\")\n",
    "    chunk['embedding'] = get_openai_embedding(combined_text)\n",
    "    if chunk['embedding']:\n",
    "        print(f\"  ‚úì Embedding created (Dimensions: {len(chunk['embedding'])})\\n\")\n",
    "    else:\n",
    "        print(f\"  ‚úó FAILED to embed chunk: {chunk['name']}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Create and Populate the Qdrant Collection\n",
    "\n",
    "Now we'll create a collection in Qdrant. A collection is like a table in a SQL database. Here, we use the modern approach to first check if the collection exists, delete it if it does, and then create a new one to ensure our notebook is runnable every time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ú® Creating new collection 'semantic_code_search'.\n",
      "‚úÖ Collection created successfully.\n",
      "\n",
      "‚úÖ Successfully upserted 3 points into the collection!\n"
     ]
    }
   ],
   "source": [
    "COLLECTION_NAME = \"semantic_code_search\"\n",
    "VECTOR_SIZE = 1536 # For text-embedding-3-small\n",
    "\n",
    "# --- Create the Collection (Modern Approach) ---\n",
    "try:\n",
    "    # Check if the collection already exists\n",
    "    collections = qdrant_client.get_collections().collections\n",
    "    collection_exists = any(collection.name == COLLECTION_NAME for collection in collections)\n",
    "    \n",
    "    if collection_exists:\n",
    "        print(f\"üóëÔ∏è Collection '{COLLECTION_NAME}' already exists. Deleting it.\")\n",
    "        qdrant_client.delete_collection(collection_name=COLLECTION_NAME)\n",
    "    \n",
    "    # Create a new collection\n",
    "    print(f\"‚ú® Creating new collection '{COLLECTION_NAME}'.\")\n",
    "    qdrant_client.create_collection(\n",
    "        collection_name=COLLECTION_NAME,\n",
    "        vectors_config=models.VectorParams(size=VECTOR_SIZE, distance=models.Distance.COSINE),\n",
    "    )\n",
    "    print(\"‚úÖ Collection created successfully.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error during collection setup: {e}\")\n",
    "\n",
    "# --- Prepare and Upsert Points ---\n",
    "points_to_upsert = []\n",
    "for chunk in enriched_chunks:\n",
    "    if chunk.get('embedding'):\n",
    "        points_to_upsert.append(\n",
    "            models.PointStruct(\n",
    "                id=str(uuid.uuid4()), \n",
    "                vector=chunk['embedding'],\n",
    "                payload={\n",
    "                    \"name\": chunk.get(\"name\"),\n",
    "                    \"code_type\": chunk.get(\"type\"),\n",
    "                    \"llm_description\": chunk.get(\"llm_description\"),\n",
    "                    \"snippet\": chunk.get(\"code\"),\n",
    "                    \"context\": {\n",
    "                        \"file_path\": chunk.get(\"file_path\"),\n",
    "                        \"line_from\": chunk.get(\"line_from\"),\n",
    "                        \"line_to\": chunk.get(\"line_to\")\n",
    "                    }\n",
    "                }\n",
    "            )\n",
    "        )\n",
    "\n",
    "if points_to_upsert:\n",
    "    try:\n",
    "        qdrant_client.upsert(\n",
    "            collection_name=COLLECTION_NAME,\n",
    "            points=points_to_upsert,\n",
    "            wait=True\n",
    "        )\n",
    "        print(f\"\\n‚úÖ Successfully upserted {len(points_to_upsert)} points into the collection!\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error upserting points: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Verify the Indexing\n",
    "\n",
    "Finally, let's ask Qdrant for information about our collection to verify that the points have been indexed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Collection Info ---\n",
      "Collection: semantic_code_search\n",
      "Indexed Vectors: 3\n",
      "\n",
      "üéâ Your data is now indexed and ready for searching!\n",
      "You can also view the collection in the Qdrant Dashboard: http://localhost:6333/dashboard\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    collection_info = qdrant_client.get_collection(collection_name=COLLECTION_NAME)\n",
    "    print(\"--- Collection Info ---\")\n",
    "    print(f\"Collection: {COLLECTION_NAME}\")\n",
    "    print(f\"Indexed Vectors: {collection_info.points_count}\")\n",
    "    print(\"\\nüéâ Your data is now indexed and ready for searching!\")\n",
    "    # Corrected Dashboard URL\n",
    "    print(\"You can also view the collection in the Qdrant Dashboard: http://localhost:6333/dashboard\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Could not retrieve collection info: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "semantic-code-search",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
