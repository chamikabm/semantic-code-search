{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Creating Embeddings with the OpenAI API\n",
    "\n",
    "This notebook demonstrates how to take the code chunks we extracted in the previous step and convert them into **vector embeddings** using OpenAI's API.\n",
    "\n",
    "## Concept\n",
    "An embedding is a numerical representation (a vector) of a piece of text or code. We will send each of our code chunks to an OpenAI embedding model, which will return a vector for each one. These vectors capture the semantic meaning of the code, allowing us to perform similarity searches later.\n",
    "\n",
    "### Pros:\n",
    "- **High Performance:** Access to state-of-the-art models without needing to train them yourself.\n",
    "- **Ease of Use:** Simple API calls abstract away complex infrastructure.\n",
    "- **Scalability:** Managed by OpenAI, so it can handle large volumes of requests.\n",
    "\n",
    "### Cons:\n",
    "- **Requires API Key & Internet:** You need a valid OpenAI API key and an internet connection.\n",
    "- **Cost:** Each API call has an associated cost, though it's generally inexpensive.\n",
    "- **Privacy:** Your code chunks are sent to OpenAI's servers for processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in /Users/cbandara/Projects/MyProjects/Learning/GenAI/semantic-code-search/.venv/lib/python3.12/site-packages (1.93.3)\n",
      "Requirement already satisfied: python-dotenv in /Users/cbandara/Projects/MyProjects/Learning/GenAI/semantic-code-search/.venv/lib/python3.12/site-packages (1.1.1)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/cbandara/Projects/MyProjects/Learning/GenAI/semantic-code-search/.venv/lib/python3.12/site-packages (from openai) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/cbandara/Projects/MyProjects/Learning/GenAI/semantic-code-search/.venv/lib/python3.12/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/cbandara/Projects/MyProjects/Learning/GenAI/semantic-code-search/.venv/lib/python3.12/site-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /Users/cbandara/Projects/MyProjects/Learning/GenAI/semantic-code-search/.venv/lib/python3.12/site-packages (from openai) (0.10.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /Users/cbandara/Projects/MyProjects/Learning/GenAI/semantic-code-search/.venv/lib/python3.12/site-packages (from openai) (2.11.7)\n",
      "Requirement already satisfied: sniffio in /Users/cbandara/Projects/MyProjects/Learning/GenAI/semantic-code-search/.venv/lib/python3.12/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /Users/cbandara/Projects/MyProjects/Learning/GenAI/semantic-code-search/.venv/lib/python3.12/site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /Users/cbandara/Projects/MyProjects/Learning/GenAI/semantic-code-search/.venv/lib/python3.12/site-packages (from openai) (4.14.1)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/cbandara/Projects/MyProjects/Learning/GenAI/semantic-code-search/.venv/lib/python3.12/site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: certifi in /Users/cbandara/Projects/MyProjects/Learning/GenAI/semantic-code-search/.venv/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai) (2025.7.9)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/cbandara/Projects/MyProjects/Learning/GenAI/semantic-code-search/.venv/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /Users/cbandara/Projects/MyProjects/Learning/GenAI/semantic-code-search/.venv/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/cbandara/Projects/MyProjects/Learning/GenAI/semantic-code-search/.venv/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /Users/cbandara/Projects/MyProjects/Learning/GenAI/semantic-code-search/.venv/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /Users/cbandara/Projects/MyProjects/Learning/GenAI/semantic-code-search/.venv/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai) (0.4.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Install the necessary libraries from OpenAI and for .env file handling\n",
    "%pip install openai python-dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and API Key Configuration\n",
    "\n",
    "First, we'll set up our OpenAI API key. The best way to do this is with a `.env` file to keep your key secure and out of your code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instructions for Using a `.env` File\n",
    "\n",
    "1.  **Create a file:** In the same directory as this notebook, create a new file named `.env`.\n",
    "2.  **Add your key:** Open the `.env` file and add your OpenAI API key in the following format:\n",
    "    ```\n",
    "    OPENAI_API_KEY=\"sk-YourSecretKeyGoesHere\"\n",
    "    ```\n",
    "3.  **Save the file.** The code below will automatically find and load this key.\n",
    "\n",
    "*(Note: If you're using Git, remember to add `.env` to your `.gitignore` file to prevent accidentally committing your secret key!)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ OpenAI client initialized successfully!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import getpass\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Get the API key\n",
    "# It will first check for the OPENAI_API_KEY in your .env file or system environment.\n",
    "# If it's not found, it will securely prompt you to enter it.\n",
    "api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
    "if not api_key:\n",
    "    api_key = getpass.getpass(\"OpenAI API key not found. Please enter your key: \")\n",
    "    os.environ[\"OPENAI_API_KEY\"] = api_key\n",
    "\n",
    "# Initialize the OpenAI client\n",
    "try:\n",
    "    client = OpenAI()\n",
    "    print(\"✅ OpenAI client initialized successfully!\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Error initializing OpenAI client: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Prepare Code Chunks\n",
    "\n",
    "Next, we'll use the code chunks we extracted in the previous notebook. For this example to be self-contained, we will redefine the list of chunks here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 5 code chunks to be embedded.\n"
     ]
    }
   ],
   "source": [
    "# This list represents the output from our previous AST chunking notebook\n",
    "code_chunks = [\n",
    "    {'name': 'read_file_content', 'type': 'function', 'code': 'def read_file_content(filepath: str) -> str:\\n    \"\"\"Read and return the content of a file.\"\"\"\\n    try:\\n        with open(filepath, \\'r\\', encoding=\\'utf-8\\') as file:\\n            return file.read()\\n    except FileNotFoundError:\\n        return \"\"'},\n",
    "    {'name': 'validate_email', 'type': 'function', 'code': 'def validate_email(email: str) -> bool:\\n    \"\"\"Simple email validation function.\"\"\"\\n    return \"@\" in email and \".\" in email.split(\"@\")[-1]'},\n",
    "    {'name': 'fetch_user_data', 'type': 'async_function', 'code': 'async def fetch_user_data(user_id: int) -> Dict:\\n    \"\"\"Async function to fetch user data from API.\"\"\"\\n    # Simulate API call\\n    await asyncio.sleep(0.1)\\n    return {\"id\": user_id, \"name\": f\"User {user_id}\"}'},\n",
    "    {'name': 'DataProcessor', 'type': 'class', 'code': 'class DataProcessor:\\n    \"\"\"A class for processing and analyzing data.\"\"\"\\n\\n    def __init__(self, data_source: str):\\n        self.data_source = data_source\\n        self.processed_count = 0\\n\\n    def process_batch(self, items: List[str]) -> List[str]:\\n        \"\"\"Process a batch of items.\"\"\"\\n        processed = []\\n        for item in items:\\n            processed.append(item.strip().upper())\\n            self.processed_count += 1\\n        return processed\\n\\n    def get_statistics(self) -> Dict[str, int]:\\n        \"\"\"Get processing statistics.\"\"\"\\n        return {\\n            \"processed_count\": self.processed_count,\\n            \"data_source_length\": len(self.data_source)\\n        }'},\n",
    "    {'name': 'FileManager', 'type': 'class', 'code': 'class FileManager:\\n    \"\"\"Utility class for file operations.\"\"\"\\n\\n    def __init__(self, base_directory: str = \".\"):\\n        self.base_directory = base_directory\\n\\n    def list_files(self, extension: str = None) -> List[str]:\\n        \"\"\"List files in the base directory.\"\"\"\\n        files = os.listdir(self.base_directory)\\n        if extension:\\n            files = [f for f in files if f.endswith(extension)]\\n        return files\\n\\n    def file_exists(self, filename: str) -> bool:\\n        \"\"\"Check if a file exists.\"\"\"\\n        return os.path.exists(os.path.join(self.base_directory, filename))'}\n",
    "]\n",
    "\n",
    "print(f\"Loaded {len(code_chunks)} code chunks to be embedded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Create Embeddings\n",
    "\n",
    "Now we'll define a function to call the OpenAI API and generate an embedding for a given piece of text. We will then loop through our code chunks and create an embedding for each one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Generating Embeddings for Code Chunks ---\n",
      "\n",
      "Processing Function 'read_file_content'...\n",
      "  ✓ Embedding created successfully!\n",
      "    Dimensions: 1536\n",
      "    Preview: [0.0472058467566967, 0.02799457125365734, -0.03252619132399559, -0.021800773218274117...]\n",
      "--------------------\n",
      "Processing Function 'validate_email'...\n",
      "  ✓ Embedding created successfully!\n",
      "    Dimensions: 1536\n",
      "    Preview: [0.012898148968815804, -0.0068848892115056515, 0.02178092859685421, -0.005763523746281862...]\n",
      "--------------------\n",
      "Processing Async Function 'fetch_user_data'...\n",
      "  ✓ Embedding created successfully!\n",
      "    Dimensions: 1536\n",
      "    Preview: [0.010124558582901955, -0.01818905770778656, -0.06986628472805023, -0.025423673912882805...]\n",
      "--------------------\n",
      "Processing Class 'DataProcessor'...\n",
      "  ✓ Embedding created successfully!\n",
      "    Dimensions: 1536\n",
      "    Preview: [-0.02076515182852745, 0.01411991287022829, -0.011680398136377335, -0.06018771603703499...]\n",
      "--------------------\n",
      "Processing Class 'FileManager'...\n",
      "  ✓ Embedding created successfully!\n",
      "    Dimensions: 1536\n",
      "    Preview: [-0.02114284411072731, 0.026010259985923767, -0.007600585930049419, -0.06358063966035843...]\n",
      "--------------------\n",
      "\n",
      "✅ Embedding process completed!\n"
     ]
    }
   ],
   "source": [
    "def get_openai_embedding(text: str, model: str = \"text-embedding-3-small\"):\n",
    "    \"\"\"Generate an embedding for a given text using OpenAI's API.\"\"\"\n",
    "    # Replace newlines with spaces, as recommended by OpenAI for older models\n",
    "    text = text.replace(\"\\n\", \" \")\n",
    "    \n",
    "    try:\n",
    "        response = client.embeddings.create(input=[text], model=model)\n",
    "        return response.data[0].embedding\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error generating embedding: {e}\")\n",
    "        return None\n",
    "\n",
    "# --- Demonstration ---\n",
    "\n",
    "print(\"--- Generating Embeddings for Code Chunks ---\\n\")\n",
    "\n",
    "embedded_chunks = []\n",
    "\n",
    "for chunk in code_chunks:\n",
    "    element_type = chunk['type'].replace('_', ' ').title()\n",
    "    name = chunk['name']\n",
    "    code = chunk['code']\n",
    "    \n",
    "    print(f\"Processing {element_type} '{name}'...\")\n",
    "    \n",
    "    # Generate embedding\n",
    "    embedding = get_openai_embedding(code)\n",
    "    \n",
    "    if embedding:\n",
    "        # Store the embedding with the original chunk data\n",
    "        chunk['embedding'] = embedding\n",
    "        embedded_chunks.append(chunk)\n",
    "        \n",
    "        # Display a preview of the embedding\n",
    "        print(f\"  ✓ Embedding created successfully!\")\n",
    "        print(f\"    Dimensions: {len(embedding)}\")\n",
    "        print(f\"    Preview: {str(embedding[:4])[:-1]}...]\")\n",
    "    else:\n",
    "        print(f\"  ✗ Failed to create embedding for '{name}'.\")\n",
    "    print(\"-\" * 20)\n",
    "\n",
    "print(\"\\n✅ Embedding process completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Final Output\n",
    "\n",
    "The `embedded_chunks` list now contains our original code chunks, each with a new `embedding` key that holds its corresponding vector. This data is now ready to be stored in a vector database for searching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Structure of the First Embedded Chunk ---\n",
      "Name: read_file_content\n",
      "Type: function\n",
      "Code:\n",
      "def read_file_content(filepath: str) -> str:\n",
      "    \"\"\"Read and return the content of a file.\"\"\"\n",
      "    try:\n",
      "        with open(filepath, 'r', encoding='utf-8') as file:\n",
      "            return file.read()\n",
      "    except FileNotFoundError:\n",
      "        return \"\"\n",
      "\n",
      "Embedding Preview: [0.0472058467566967, 0.02799457125365734, -0.03252619132399559, -0.021800773218274117...]\n"
     ]
    }
   ],
   "source": [
    "# Inspect the first embedded chunk to see the final structure\n",
    "if embedded_chunks:\n",
    "    print(\"--- Structure of the First Embedded Chunk ---\")\n",
    "    first_chunk = embedded_chunks[0]\n",
    "    print(f\"Name: {first_chunk['name']}\")\n",
    "    print(f\"Type: {first_chunk['type']}\")\n",
    "    print(f\"Code:\\n{first_chunk['code']}\\n\")\n",
    "    print(f\"Embedding Preview: {str(first_chunk['embedding'][:4])[:-1]}...]\")\n",
    "else:\n",
    "    print(\"No chunks were embedded. Please check your API key and network connection.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "semantic-code-search",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
