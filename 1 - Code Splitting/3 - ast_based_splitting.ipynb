{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Method 3: AST-Based (Language-Aware) Splitting\n",
    "\n",
    "This notebook demonstrates the gold standard for code chunking: **AST-Based Splitting**.\n",
    "\n",
    "## Concept\n",
    "This method parses the source code into an **Abstract Syntax Tree (AST)**, which is a formal representation of the code's structure. By traversing this tree, we can extract complete, syntactically correct nodes like functions and classes.\n",
    "\n",
    "### Pros:\n",
    "- **Maximally Semantic:** Chunks are inherently meaningful because they align with the code's logical structure.\n",
    "- **High-Quality Embeddings:** Coherent chunks produce accurate and useful embeddings.\n",
    "- **Precise Retrieval:** Allows a search query to point to the exact function or class that is relevant.\n",
    "- **Multi-Language Support:** Works with multiple programming languages using tree-sitter.\n",
    "\n",
    "### Cons:\n",
    "- **More Complex to Implement:** Requires integrating a parser like `tree-sitter` and writing language-specific logic.\n",
    "- **Language-Specific:** Needs the correct grammar/parser for each programming language.\n",
    "- **Version Dependencies:** Requires compatible versions of tree-sitter libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔄 Removing any existing incompatible versions...\n",
      "📦 Installing compatible versions...\n",
      "📦 Installing compatible versions...\n",
      "✓ tree-sitter==0.20.4 installed successfully\n",
      "✓ tree-sitter==0.20.4 installed successfully\n",
      "✓ tree_sitter_languages==1.9.1 installed successfully\n",
      "\n",
      "🔍 Verifying installation...\n",
      "✅ tree_sitter_languages is working correctly!\n",
      "\n",
      "🎉 All packages are working correctly!\n",
      "✓ tree_sitter_languages==1.9.1 installed successfully\n",
      "\n",
      "🔍 Verifying installation...\n",
      "✅ tree_sitter_languages is working correctly!\n",
      "\n",
      "🎉 All packages are working correctly!\n"
     ]
    }
   ],
   "source": [
    "# Install compatible versions of tree-sitter libraries\n",
    "# Note: These specific versions are required for compatibility\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "def install_compatible_packages():\n",
    "    \"\"\"Install compatible versions that work together\"\"\"\n",
    "    \n",
    "    # First, uninstall any existing versions\n",
    "    print(\"🔄 Removing any existing incompatible versions...\")\n",
    "    try:\n",
    "        subprocess.run([sys.executable, \"-m\", \"pip\", \"uninstall\", \"tree-sitter\", \"tree-sitter-languages\", \"-y\"], \n",
    "                      capture_output=True)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    # Install the compatible versions (using available versions)\n",
    "    print(\"📦 Installing compatible versions...\")\n",
    "    packages = [\n",
    "        \"tree-sitter==0.20.4\",\n",
    "        \"tree_sitter_languages==1.9.1\"  # Available version that should work\n",
    "    ]\n",
    "    \n",
    "    for package in packages:\n",
    "        try:\n",
    "            result = subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", package], \n",
    "                                  capture_output=True, text=True)\n",
    "            if result.returncode == 0:\n",
    "                print(f\"✓ {package} installed successfully\")\n",
    "            else:\n",
    "                print(f\"✗ Error installing {package}: {result.stderr}\")\n",
    "        except Exception as e:\n",
    "            print(f\"✗ Exception installing {package}: {e}\")\n",
    "    \n",
    "    # Verify installation\n",
    "    print(\"\\n🔍 Verifying installation...\")\n",
    "    try:\n",
    "        from tree_sitter_languages import get_parser\n",
    "        parser = get_parser('python')\n",
    "        print(\"✅ tree_sitter_languages is working correctly!\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Verification failed: {e}\")\n",
    "        return False\n",
    "\n",
    "success = install_compatible_packages()\n",
    "if success:\n",
    "    print(\"\\n🎉 All packages are working correctly!\")\n",
    "else:\n",
    "    print(\"\\n⚠️  Installation issues detected. You may need to restart the kernel.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample Code for Demonstration\n",
    "We will use the following block of Python code as the input to demonstrate AST-based splitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample code loaded:\n",
      "\n",
      "# File management and data processing utilities\n",
      "\n",
      "import os\n",
      "from typing import List, Dict\n",
      "import asyncio\n",
      "\n",
      "def read_file_content(filepath: str) -> str:\n",
      "    \"\"\"Read and return the content of a file.\"\"\"\n",
      "    try:\n",
      "        with open(filepath, 'r', encoding='utf-8') as file:\n",
      "            return file.read()\n",
      "    except FileNotFoundError:\n",
      "        return \"\"\n",
      "\n",
      "def validate_email(email: str) -> bool:\n",
      "    \"\"\"Simple email validation function.\"\"\"\n",
      "    return \"@\" in email and \".\" in email.split(\"@\")[-1]\n",
      "\n",
      "async def fetch_user_data(user_id: int) -> Dict:\n",
      "    \"\"\"Async function to fetch user data from API.\"\"\"\n",
      "    # Simulate API call\n",
      "    await asyncio.sleep(0.1)\n",
      "    return {\"id\": user_id, \"name\": f\"User {user_id}\"}\n",
      "\n",
      "class DataProcessor:\n",
      "    \"\"\"A class for processing and analyzing data.\"\"\"\n",
      "\n",
      "    def __init__(self, data_source: str):\n",
      "        self.data_source = data_source\n",
      "        self.processed_count = 0\n",
      "\n",
      "    def process_batch(self, items: List[str]) -> List[str]:\n",
      "        \"\"\"Process a batch of items.\"\"\"\n",
      "        processed = []\n",
      "        for item in items:\n",
      "            processed.append(item.strip().upper())\n",
      "            self.processed_count += 1\n",
      "        return processed\n",
      "\n",
      "    def get_statistics(self) -> Dict[str, int]:\n",
      "        \"\"\"Get processing statistics.\"\"\"\n",
      "        return {\n",
      "            \"processed_count\": self.processed_count,\n",
      "            \"data_source_length\": len(self.data_source)\n",
      "        }\n",
      "\n",
      "class FileManager:\n",
      "    \"\"\"Utility class for file operations.\"\"\"\n",
      "\n",
      "    def __init__(self, base_directory: str = \".\"):\n",
      "        self.base_directory = base_directory\n",
      "\n",
      "    def list_files(self, extension: str = None) -> List[str]:\n",
      "        \"\"\"List files in the base directory.\"\"\"\n",
      "        files = os.listdir(self.base_directory)\n",
      "        if extension:\n",
      "            files = [f for f in files if f.endswith(extension)]\n",
      "        return files\n",
      "\n",
      "    def file_exists(self, filename: str) -> bool:\n",
      "        \"\"\"Check if a file exists.\"\"\"\n",
      "        return os.path.exists(os.path.join(self.base_directory, filename))\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sample_code = \"\"\"\n",
    "# File management and data processing utilities\n",
    "\n",
    "import os\n",
    "from typing import List, Dict\n",
    "import asyncio\n",
    "\n",
    "def read_file_content(filepath: str) -> str:\n",
    "    \\\"\\\"\\\"Read and return the content of a file.\\\"\\\"\\\"\n",
    "    try:\n",
    "        with open(filepath, 'r', encoding='utf-8') as file:\n",
    "            return file.read()\n",
    "    except FileNotFoundError:\n",
    "        return \"\"\n",
    "\n",
    "def validate_email(email: str) -> bool:\n",
    "    \\\"\\\"\\\"Simple email validation function.\\\"\\\"\\\"\n",
    "    return \"@\" in email and \".\" in email.split(\"@\")[-1]\n",
    "\n",
    "async def fetch_user_data(user_id: int) -> Dict:\n",
    "    \\\"\\\"\\\"Async function to fetch user data from API.\\\"\\\"\\\"\n",
    "    # Simulate API call\n",
    "    await asyncio.sleep(0.1)\n",
    "    return {\"id\": user_id, \"name\": f\"User {user_id}\"}\n",
    "\n",
    "class DataProcessor:\n",
    "    \\\"\\\"\\\"A class for processing and analyzing data.\\\"\\\"\\\"\n",
    "    \n",
    "    def __init__(self, data_source: str):\n",
    "        self.data_source = data_source\n",
    "        self.processed_count = 0\n",
    "    \n",
    "    def process_batch(self, items: List[str]) -> List[str]:\n",
    "        \\\"\\\"\\\"Process a batch of items.\\\"\\\"\\\"\n",
    "        processed = []\n",
    "        for item in items:\n",
    "            processed.append(item.strip().upper())\n",
    "            self.processed_count += 1\n",
    "        return processed\n",
    "    \n",
    "    def get_statistics(self) -> Dict[str, int]:\n",
    "        \\\"\\\"\\\"Get processing statistics.\\\"\\\"\\\"\n",
    "        return {\n",
    "            \"processed_count\": self.processed_count,\n",
    "            \"data_source_length\": len(self.data_source)\n",
    "        }\n",
    "\n",
    "class FileManager:\n",
    "    \\\"\\\"\\\"Utility class for file operations.\\\"\\\"\\\"\n",
    "    \n",
    "    def __init__(self, base_directory: str = \".\"):\n",
    "        self.base_directory = base_directory\n",
    "    \n",
    "    def list_files(self, extension: str = None) -> List[str]:\n",
    "        \\\"\\\"\\\"List files in the base directory.\\\"\\\"\\\"\n",
    "        files = os.listdir(self.base_directory)\n",
    "        if extension:\n",
    "            files = [f for f in files if f.endswith(extension)]\n",
    "        return files\n",
    "    \n",
    "    def file_exists(self, filename: str) -> bool:\n",
    "        \\\"\\\"\\\"Check if a file exists.\\\"\\\"\\\"\n",
    "        return os.path.exists(os.path.join(self.base_directory, filename))\n",
    "\"\"\"\n",
    "\n",
    "print(\"Sample code loaded:\")\n",
    "print(sample_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Code extraction functions defined\n"
     ]
    }
   ],
   "source": [
    "from tree_sitter_languages import get_parser\n",
    "\n",
    "def extract_code_elements(code: str, language: str = 'python'):\n",
    "    \"\"\"\n",
    "    Extract classes and functions from source code using tree-sitter AST parsing.\n",
    "    Similar to the working approach but with improved structure.\n",
    "    \n",
    "    Args:\n",
    "        code (str): The source code to analyze\n",
    "        language (str): Programming language (default: 'python')\n",
    "    \n",
    "    Returns:\n",
    "        dict: Dictionary containing extracted classes and functions\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Initialize parser\n",
    "        parser = get_parser(language)\n",
    "        \n",
    "        # Parse code into AST\n",
    "        tree = parser.parse(bytes(code, \"utf8\"))\n",
    "        \n",
    "        # Results container\n",
    "        extracted_elements = {\n",
    "            'classes': [],\n",
    "            'functions': [],\n",
    "            'async_functions': []\n",
    "        }\n",
    "        \n",
    "        def traverse_ast(node):\n",
    "            \"\"\"Recursively traverse the AST and extract code elements.\"\"\"\n",
    "            \n",
    "            # Extract class definitions\n",
    "            if node.type == \"class_definition\":\n",
    "                class_name = node.child_by_field_name(\"name\").text.decode('utf8')\n",
    "                class_code = node.text.decode('utf8')\n",
    "                extracted_elements['classes'].append({\n",
    "                    'name': class_name,\n",
    "                    'code': class_code,\n",
    "                    'type': 'class'\n",
    "                })\n",
    "            \n",
    "            # Extract regular function definitions\n",
    "            elif node.type == \"function_definition\":\n",
    "                func_name = node.child_by_field_name(\"name\").text.decode('utf8')\n",
    "                func_code = node.text.decode('utf8')\n",
    "                extracted_elements['functions'].append({\n",
    "                    'name': func_name,\n",
    "                    'code': func_code,\n",
    "                    'type': 'function'\n",
    "                })\n",
    "            \n",
    "            # Extract async function definitions\n",
    "            elif node.type == \"async_function_definition\":\n",
    "                async_func_name = node.child_by_field_name(\"name\").text.decode('utf8')\n",
    "                async_func_code = node.text.decode('utf8')\n",
    "                extracted_elements['async_functions'].append({\n",
    "                    'name': async_func_name,\n",
    "                    'code': async_func_code,\n",
    "                    'type': 'async_function'\n",
    "                })\n",
    "            \n",
    "            # Recursively process child nodes\n",
    "            for child in node.children:\n",
    "                traverse_ast(child)\n",
    "        \n",
    "        # Start traversal from root\n",
    "        traverse_ast(tree.root_node)\n",
    "        return extracted_elements\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting code elements: {e}\")\n",
    "        return {'classes': [], 'functions': [], 'async_functions': []}\n",
    "\n",
    "def group_all_elements(extracted_elements):\n",
    "    \"\"\"\n",
    "    Group all extracted elements into a single list for easier processing.\n",
    "    \n",
    "    Args:\n",
    "        extracted_elements (dict): Dictionary from extract_code_elements\n",
    "    \n",
    "    Returns:\n",
    "        list: All elements combined with their metadata\n",
    "    \"\"\"\n",
    "    all_elements = []\n",
    "    \n",
    "    # Add classes\n",
    "    all_elements.extend(extracted_elements['classes'])\n",
    "    \n",
    "    # Add regular functions\n",
    "    all_elements.extend(extracted_elements['functions'])\n",
    "    \n",
    "    # Add async functions\n",
    "    all_elements.extend(extracted_elements['async_functions'])\n",
    "    \n",
    "    return all_elements\n",
    "\n",
    "def display_element(element, index=None):\n",
    "    \"\"\"\n",
    "    Display a single code element in a formatted way.\n",
    "    \n",
    "    Args:\n",
    "        element (dict): Element dictionary with name, code, and type\n",
    "        index (int): Optional index for numbering\n",
    "    \"\"\"\n",
    "    element_type = element['type'].replace('_', ' ').title()\n",
    "    name = element['name']\n",
    "    code = element['code']\n",
    "    \n",
    "    if index is not None:\n",
    "        print(f\"--- Element {index}: {element_type} '{name}' ---\")\n",
    "    else:\n",
    "        print(f\"--- {element_type} '{name}' ---\")\n",
    "    \n",
    "    print(code)\n",
    "    print()  # Add spacing\n",
    "\n",
    "def display_elements_by_type(extracted_elements):\n",
    "    \"\"\"\n",
    "    Display elements grouped by their type.\n",
    "    \n",
    "    Args:\n",
    "        extracted_elements (dict): Dictionary from extract_code_elements\n",
    "    \"\"\"\n",
    "    # Display classes\n",
    "    if extracted_elements['classes']:\n",
    "        print(\"🏛️  CLASSES:\")\n",
    "        print(\"=\" * 50)\n",
    "        for element in extracted_elements['classes']:\n",
    "            display_element(element)\n",
    "    \n",
    "    # Display functions\n",
    "    if extracted_elements['functions']:\n",
    "        print(\"⚡ FUNCTIONS:\")\n",
    "        print(\"=\" * 50)\n",
    "        for element in extracted_elements['functions']:\n",
    "            display_element(element)\n",
    "    \n",
    "    # Display async functions\n",
    "    if extracted_elements['async_functions']:\n",
    "        print(\"🔄 ASYNC FUNCTIONS:\")\n",
    "        print(\"=\" * 50)\n",
    "        for element in extracted_elements['async_functions']:\n",
    "            display_element(element)\n",
    "\n",
    "print(\"✓ Code extraction functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demonstration\n",
    "\n",
    "Let's apply the AST-based splitting to our sample code and see the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Method 3: AST-Based Splitting (using tree-sitter-languages) ---\n",
      "This method extracts complete functions and classes as semantically meaningful chunks.\n",
      "Supports multiple programming languages!\n",
      "\n",
      "📊 EXTRACTION SUMMARY:\n",
      "   Classes: 2\n",
      "   Functions: 9\n",
      "   Async Functions: 0\n",
      "   Total Elements: 11\n",
      "\n",
      "🏛️  CLASSES:\n",
      "==================================================\n",
      "--- Class 'DataProcessor' ---\n",
      "class DataProcessor:\n",
      "    \"\"\"A class for processing and analyzing data.\"\"\"\n",
      "\n",
      "    def __init__(self, data_source: str):\n",
      "        self.data_source = data_source\n",
      "        self.processed_count = 0\n",
      "\n",
      "    def process_batch(self, items: List[str]) -> List[str]:\n",
      "        \"\"\"Process a batch of items.\"\"\"\n",
      "        processed = []\n",
      "        for item in items:\n",
      "            processed.append(item.strip().upper())\n",
      "            self.processed_count += 1\n",
      "        return processed\n",
      "\n",
      "    def get_statistics(self) -> Dict[str, int]:\n",
      "        \"\"\"Get processing statistics.\"\"\"\n",
      "        return {\n",
      "            \"processed_count\": self.processed_count,\n",
      "            \"data_source_length\": len(self.data_source)\n",
      "        }\n",
      "\n",
      "--- Class 'FileManager' ---\n",
      "class FileManager:\n",
      "    \"\"\"Utility class for file operations.\"\"\"\n",
      "\n",
      "    def __init__(self, base_directory: str = \".\"):\n",
      "        self.base_directory = base_directory\n",
      "\n",
      "    def list_files(self, extension: str = None) -> List[str]:\n",
      "        \"\"\"List files in the base directory.\"\"\"\n",
      "        files = os.listdir(self.base_directory)\n",
      "        if extension:\n",
      "            files = [f for f in files if f.endswith(extension)]\n",
      "        return files\n",
      "\n",
      "    def file_exists(self, filename: str) -> bool:\n",
      "        \"\"\"Check if a file exists.\"\"\"\n",
      "        return os.path.exists(os.path.join(self.base_directory, filename))\n",
      "\n",
      "⚡ FUNCTIONS:\n",
      "==================================================\n",
      "--- Function 'read_file_content' ---\n",
      "def read_file_content(filepath: str) -> str:\n",
      "    \"\"\"Read and return the content of a file.\"\"\"\n",
      "    try:\n",
      "        with open(filepath, 'r', encoding='utf-8') as file:\n",
      "            return file.read()\n",
      "    except FileNotFoundError:\n",
      "        return \"\"\n",
      "\n",
      "--- Function 'validate_email' ---\n",
      "def validate_email(email: str) -> bool:\n",
      "    \"\"\"Simple email validation function.\"\"\"\n",
      "    return \"@\" in email and \".\" in email.split(\"@\")[-1]\n",
      "\n",
      "--- Function 'fetch_user_data' ---\n",
      "async def fetch_user_data(user_id: int) -> Dict:\n",
      "    \"\"\"Async function to fetch user data from API.\"\"\"\n",
      "    # Simulate API call\n",
      "    await asyncio.sleep(0.1)\n",
      "    return {\"id\": user_id, \"name\": f\"User {user_id}\"}\n",
      "\n",
      "--- Function '__init__' ---\n",
      "def __init__(self, data_source: str):\n",
      "        self.data_source = data_source\n",
      "        self.processed_count = 0\n",
      "\n",
      "--- Function 'process_batch' ---\n",
      "def process_batch(self, items: List[str]) -> List[str]:\n",
      "        \"\"\"Process a batch of items.\"\"\"\n",
      "        processed = []\n",
      "        for item in items:\n",
      "            processed.append(item.strip().upper())\n",
      "            self.processed_count += 1\n",
      "        return processed\n",
      "\n",
      "--- Function 'get_statistics' ---\n",
      "def get_statistics(self) -> Dict[str, int]:\n",
      "        \"\"\"Get processing statistics.\"\"\"\n",
      "        return {\n",
      "            \"processed_count\": self.processed_count,\n",
      "            \"data_source_length\": len(self.data_source)\n",
      "        }\n",
      "\n",
      "--- Function '__init__' ---\n",
      "def __init__(self, base_directory: str = \".\"):\n",
      "        self.base_directory = base_directory\n",
      "\n",
      "--- Function 'list_files' ---\n",
      "def list_files(self, extension: str = None) -> List[str]:\n",
      "        \"\"\"List files in the base directory.\"\"\"\n",
      "        files = os.listdir(self.base_directory)\n",
      "        if extension:\n",
      "            files = [f for f in files if f.endswith(extension)]\n",
      "        return files\n",
      "\n",
      "--- Function 'file_exists' ---\n",
      "def file_exists(self, filename: str) -> bool:\n",
      "        \"\"\"Check if a file exists.\"\"\"\n",
      "        return os.path.exists(os.path.join(self.base_directory, filename))\n",
      "\n",
      "============================================================\n",
      "✅ AST-based extraction completed successfully!\n",
      "✅ All code elements extracted with semantic boundaries preserved\n"
     ]
    }
   ],
   "source": [
    "print(\"--- Method 3: AST-Based Splitting (using tree-sitter-languages) ---\")\n",
    "\n",
    "# Extract code elements using our new function\n",
    "extracted_elements = extract_code_elements(sample_code, language='python')\n",
    "\n",
    "# Get summary statistics\n",
    "total_classes = len(extracted_elements['classes'])\n",
    "total_functions = len(extracted_elements['functions'])\n",
    "total_async_functions = len(extracted_elements['async_functions'])\n",
    "total_elements = total_classes + total_functions + total_async_functions\n",
    "\n",
    "print(f\"📊 EXTRACTION SUMMARY:\")\n",
    "print(f\"   Classes: {total_classes}\")\n",
    "print(f\"   Functions: {total_functions}\")\n",
    "print(f\"   Async Functions: {total_async_functions}\")\n",
    "print(f\"   Total Elements: {total_elements}\")\n",
    "print()\n",
    "\n",
    "# Display elements grouped by type\n",
    "display_elements_by_type(extracted_elements)\n",
    "\n",
    "print(\"=\" * 60)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
